{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "56c0d4cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-09-12 14:04:15,214] [INFO] [real_accelerator.py:260:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/diffusion/bin/../lib/gcc/x86_64-conda-linux-gnu/13.3.0/../../../../x86_64-conda-linux-gnu/bin/ld: cannot find -laio: No such file or directory\n",
      "collect2: error: ld returned 1 exit status\n",
      "/opt/anaconda3/envs/diffusion/bin/../lib/gcc/x86_64-conda-linux-gnu/13.3.0/../../../../x86_64-conda-linux-gnu/bin/ld: cannot find -laio: No such file or directory\n",
      "collect2: error: ld returned 1 exit status\n",
      "/opt/anaconda3/envs/diffusion/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-09-12 14:04:16,371] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "from utils.model import extract_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "31340e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorboard.backend.event_processing.event_accumulator import EventAccumulator\n",
    "\n",
    "\n",
    "# def extract_metrics(log_dir: str) -> dict:\n",
    "#     \"\"\"\n",
    "#     Extracts the latest scalar metrics from TensorBoard logs.\n",
    "\n",
    "#     This function reads the TensorBoard event files in the specified log directory\n",
    "#     and extracts the latest value for each scalar metric.\n",
    "\n",
    "#     Args:\n",
    "#         log_dir (str): Path to the directory containing TensorBoard event files.\n",
    "\n",
    "#     Returns:\n",
    "#         dict: A dictionary where keys are metric tags and values are the latest scalar values.\n",
    "#     \"\"\"\n",
    "#     accumulator = EventAccumulator(log_dir)\n",
    "#     accumulator.Reload()\n",
    "#     metrics = {}\n",
    "#     for tag in accumulator.Tags()[\"scalars\"]:\n",
    "#         events = accumulator.Scalars(tag)\n",
    "#         # print(events)\n",
    "#         if events:\n",
    "#             metrics[tag] = events[-1].value\n",
    "#     return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c1fe14d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ORDER = [\n",
    "    \"metric_gyr_pearson_X/test\",\n",
    "    \"metric_gyr_pearson_Y/test\",\n",
    "    \"metric_gyr_pearson_Z/test\",\n",
    "    \"metric_gyr_pearson_norm/test\",\n",
    "    \"metric_gyr_simVector_X/test\",\n",
    "    \"metric_gyr_simVector_Y/test\",\n",
    "    \"metric_gyr_simVector_Z/test\",\n",
    "    \"metric_gyr_simVector_norm/test\",\n",
    "    \"metric_gyr_simVector/test\",\n",
    "    # \"metric_mse_gyr_X/test\",\n",
    "    # \"metric_mse_gyr_Y/test\",\n",
    "    # \"metric_mse_gyr_Z/test\",\n",
    "    # \"metric_mse_gyr/test\",\n",
    "    \"metric_naive_Angular_error_X/test\",\n",
    "    \"metric_naive_Angular_error_Y/test\",\n",
    "    \"metric_naive_Angular_error_Z/test\",\n",
    "    \"metric_naive_Angular_error/test\",\n",
    "    #\n",
    "    \"metric_acc_pearson_X/test\",\n",
    "    \"metric_acc_pearson_Y/test\",\n",
    "    \"metric_acc_pearson_Z/test\",\n",
    "    \"metric_acc_pearson_norm/test\",\n",
    "    \"metric_acc_simVector_X/test\",\n",
    "    \"metric_acc_simVector_Y/test\",\n",
    "    \"metric_acc_simVector_Z/test\",\n",
    "    \"metric_acc_simVector_norm/test\",\n",
    "    \"metric_acc_simVector/test\",\n",
    "    # \"metric_mse_acc_X/test\",\n",
    "    # \"metric_mse_acc_Y/test\",\n",
    "    # \"metric_mse_acc_Z/test\",\n",
    "    # \"metric_mse_acc/test\",\n",
    "    \"metric_naive_distance_error_X/test\",\n",
    "    \"metric_naive_distance_error_Y/test\",\n",
    "    \"metric_naive_distance_error_Z/test\",\n",
    "    \"metric_naive_distance_error/test\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "45feb115",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_logs = Path(\"logs/diffusion_OIOD/baseline\")\n",
    "target_logs = Path(\"logs/diffusion_OIOD/version_0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f53797a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_logs_metrics = extract_metrics(str(baseline_logs))\n",
    "target_logs_matrics = extract_metrics(str(target_logs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e9d7f5ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metric_acc_pearson_X/test: 0.7213637828826904 -> 0.9755808711051941\n",
      "metric_acc_pearson_Y/test: 0.46427881717681885 -> 0.9771765470504761\n",
      "metric_acc_pearson_Z/test: -0.1268456131219864 -> 0.6259234547615051\n",
      "metric_acc_pearson_norm/test: 0.5844262838363647 -> 0.9417152404785156\n",
      "metric_acc_simVector/test: 0.3721754252910614 -> 0.8182361125946045\n",
      "metric_acc_simVector_X/test: 0.6823089122772217 -> 0.9447945356369019\n",
      "metric_acc_simVector_Y/test: 0.5231196284294128 -> 0.9317184686660767\n",
      "metric_acc_simVector_Z/test: -0.08890233188867569 -> 0.5781954526901245\n",
      "metric_acc_simVector_norm/test: 0.9635938405990601 -> 0.9824695587158203\n",
      "metric_naive_distance_error_X/test: 0.21232858300209045 -> 0.034206829965114594\n",
      "metric_naive_distance_error_Y/test: 0.2745972275733948 -> 0.041199345141649246\n",
      "metric_naive_distance_error_Z/test: 0.25316575169563293 -> 0.010370557196438313\n",
      "metric_naive_distance_error/test: 0.6400293707847595 -> 0.11229421198368073\n",
      "metric_gyr_pearson_X/test: -0.055152177810668945 -> 0.1045088842511177\n",
      "metric_gyr_pearson_Y/test: -0.09120780974626541 -> 0.24903742969036102\n",
      "metric_gyr_pearson_Z/test: 0.7504726648330688 -> 0.9806596040725708\n",
      "metric_gyr_pearson_norm/test: 0.8423279523849487 -> 0.8412852883338928\n",
      "metric_gyr_simVector/test: 0.19422052800655365 -> 0.6522698998451233\n",
      "metric_gyr_simVector_X/test: -0.15344394743442535 -> 0.508807361125946\n",
      "metric_gyr_simVector_Y/test: -0.07237347960472107 -> 0.4999639093875885\n",
      "metric_gyr_simVector_Z/test: 0.8084789514541626 -> 0.9480385184288025\n",
      "metric_gyr_simVector_norm/test: 0.9859704971313477 -> 0.9824661016464233\n",
      "metric_naive_Angular_error_X/test: 0.0961255356669426 -> 0.022963088005781174\n",
      "metric_naive_Angular_error_Y/test: 0.08765581250190735 -> 0.015787459909915924\n",
      "metric_naive_Angular_error_Z/test: 0.13015221059322357 -> 0.019432432949543\n",
      "metric_naive_Angular_error/test: 0.5699332356452942 -> 0.06560640782117844\n",
      "                                metric  baseline  baseline_std    result  \\\n",
      "0            metric_acc_pearson_X/test  0.721364      0.721364  0.975581   \n",
      "1            metric_acc_pearson_Y/test  0.464279      0.464279  0.977177   \n",
      "2            metric_acc_pearson_Z/test -0.126846     -0.126846  0.625923   \n",
      "3         metric_acc_pearson_norm/test  0.584426      0.584426  0.941715   \n",
      "4            metric_acc_simVector/test  0.372175      0.372175  0.818236   \n",
      "5          metric_acc_simVector_X/test  0.682309      0.682309  0.944795   \n",
      "6          metric_acc_simVector_Y/test  0.523120      0.523120  0.931718   \n",
      "7          metric_acc_simVector_Z/test -0.088902     -0.088902  0.578195   \n",
      "8       metric_acc_simVector_norm/test  0.963594      0.963594  0.982470   \n",
      "9   metric_naive_distance_error_X/test  0.212329      0.212329  0.034207   \n",
      "10  metric_naive_distance_error_Y/test  0.274597      0.274597  0.041199   \n",
      "11  metric_naive_distance_error_Z/test  0.253166      0.253166  0.010371   \n",
      "12    metric_naive_distance_error/test  0.640029      0.640029  0.112294   \n",
      "13           metric_gyr_pearson_X/test -0.055152     -0.055152  0.104509   \n",
      "14           metric_gyr_pearson_Y/test -0.091208     -0.091208  0.249037   \n",
      "15           metric_gyr_pearson_Z/test  0.750473      0.750473  0.980660   \n",
      "16        metric_gyr_pearson_norm/test  0.842328      0.842328  0.841285   \n",
      "17           metric_gyr_simVector/test  0.194221      0.194221  0.652270   \n",
      "18         metric_gyr_simVector_X/test -0.153444     -0.153444  0.508807   \n",
      "19         metric_gyr_simVector_Y/test -0.072373     -0.072373  0.499964   \n",
      "20         metric_gyr_simVector_Z/test  0.808479      0.808479  0.948039   \n",
      "21      metric_gyr_simVector_norm/test  0.985970      0.985970  0.982466   \n",
      "22   metric_naive_Angular_error_X/test  0.096126      0.096126  0.022963   \n",
      "23   metric_naive_Angular_error_Y/test  0.087656      0.087656  0.015787   \n",
      "24   metric_naive_Angular_error_Z/test  0.130152      0.130152  0.019432   \n",
      "25     metric_naive_Angular_error/test  0.569933      0.569933  0.065606   \n",
      "\n",
      "    result_std  \n",
      "0     0.975581  \n",
      "1     0.977177  \n",
      "2     0.625923  \n",
      "3     0.941715  \n",
      "4     0.818236  \n",
      "5     0.944795  \n",
      "6     0.931718  \n",
      "7     0.578195  \n",
      "8     0.982470  \n",
      "9     0.034207  \n",
      "10    0.041199  \n",
      "11    0.010371  \n",
      "12    0.112294  \n",
      "13    0.104509  \n",
      "14    0.249037  \n",
      "15    0.980660  \n",
      "16    0.841285  \n",
      "17    0.652270  \n",
      "18    0.508807  \n",
      "19    0.499964  \n",
      "20    0.948039  \n",
      "21    0.982466  \n",
      "22    0.022963  \n",
      "23    0.015787  \n",
      "24    0.019432  \n",
      "25    0.065606  \n"
     ]
    }
   ],
   "source": [
    "# create df with column name baseline and result\n",
    "data = []\n",
    "for key, value in baseline_logs_metrics.items():\n",
    "    # Assuming value is a list of tuples and we want the first tuple's second element\n",
    "\n",
    "    if key.replace(\"_mean\", \"\") not in ORDER:\n",
    "        continue\n",
    "\n",
    "    baseline_val = value[0][1] if value and len(value[0]) > 1 else None\n",
    "    target_val = (\n",
    "        target_logs_matrics.get(key, [(None, None)])[0][1]\n",
    "        if target_logs_matrics.get(key) and len(target_logs_matrics[key][0]) > 1\n",
    "        else None\n",
    "    )\n",
    "    std_key = key.replace(\"_mean\", \"_std\")\n",
    "    baseline_std = (\n",
    "        baseline_logs_metrics.get(std_key, [(None, None)])[0][1]\n",
    "        if baseline_logs_metrics.get(std_key)\n",
    "        and len(baseline_logs_metrics[std_key][0]) > 1\n",
    "        else None\n",
    "    )\n",
    "    target_std = (\n",
    "        target_logs_matrics.get(std_key, [(None, None)])[0][1]\n",
    "        if target_logs_matrics.get(std_key) and len(target_logs_matrics[std_key][0]) > 1\n",
    "        else None\n",
    "    )\n",
    "    print(\n",
    "        f\"{key}: {baseline_val} -> {target_logs_matrics.get(key, [(None, None)])[0][1]}\"\n",
    "    )\n",
    "    data.append(\n",
    "        {\n",
    "            \"metric\": key.replace(\"_mean\", \"\"),\n",
    "            \"baseline\": baseline_val,\n",
    "            \"baseline_std\": baseline_std,\n",
    "            \"result\": target_val,\n",
    "            \"result_std\": target_std,\n",
    "        }\n",
    "    )\n",
    "\n",
    "df = pd.DataFrame.from_dict(data)\n",
    "print(df.head(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5df7b3ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                metric  baseline  baseline_std    result  \\\n",
      "0            metric_gyr_pearson_X/test -0.055152     -0.055152  0.104509   \n",
      "1            metric_gyr_pearson_Y/test -0.091208     -0.091208  0.249037   \n",
      "2            metric_gyr_pearson_Z/test  0.750473      0.750473  0.980660   \n",
      "3         metric_gyr_pearson_norm/test  0.842328      0.842328  0.841285   \n",
      "4          metric_gyr_simVector_X/test -0.153444     -0.153444  0.508807   \n",
      "5          metric_gyr_simVector_Y/test -0.072373     -0.072373  0.499964   \n",
      "6          metric_gyr_simVector_Z/test  0.808479      0.808479  0.948039   \n",
      "7       metric_gyr_simVector_norm/test  0.985970      0.985970  0.982466   \n",
      "8            metric_gyr_simVector/test  0.194221      0.194221  0.652270   \n",
      "9    metric_naive_Angular_error_X/test  0.096126      0.096126  0.022963   \n",
      "10   metric_naive_Angular_error_Y/test  0.087656      0.087656  0.015787   \n",
      "11   metric_naive_Angular_error_Z/test  0.130152      0.130152  0.019432   \n",
      "12     metric_naive_Angular_error/test  0.569933      0.569933  0.065606   \n",
      "13           metric_acc_pearson_X/test  0.721364      0.721364  0.975581   \n",
      "14           metric_acc_pearson_Y/test  0.464279      0.464279  0.977177   \n",
      "15           metric_acc_pearson_Z/test -0.126846     -0.126846  0.625923   \n",
      "16        metric_acc_pearson_norm/test  0.584426      0.584426  0.941715   \n",
      "17         metric_acc_simVector_X/test  0.682309      0.682309  0.944795   \n",
      "18         metric_acc_simVector_Y/test  0.523120      0.523120  0.931718   \n",
      "19         metric_acc_simVector_Z/test -0.088902     -0.088902  0.578195   \n",
      "20      metric_acc_simVector_norm/test  0.963594      0.963594  0.982470   \n",
      "21           metric_acc_simVector/test  0.372175      0.372175  0.818236   \n",
      "22  metric_naive_distance_error_X/test  0.212329      0.212329  0.034207   \n",
      "23  metric_naive_distance_error_Y/test  0.274597      0.274597  0.041199   \n",
      "24  metric_naive_distance_error_Z/test  0.253166      0.253166  0.010371   \n",
      "25    metric_naive_distance_error/test  0.640029      0.640029  0.112294   \n",
      "\n",
      "    result_std  \n",
      "0     0.104509  \n",
      "1     0.249037  \n",
      "2     0.980660  \n",
      "3     0.841285  \n",
      "4     0.508807  \n",
      "5     0.499964  \n",
      "6     0.948039  \n",
      "7     0.982466  \n",
      "8     0.652270  \n",
      "9     0.022963  \n",
      "10    0.015787  \n",
      "11    0.019432  \n",
      "12    0.065606  \n",
      "13    0.975581  \n",
      "14    0.977177  \n",
      "15    0.625923  \n",
      "16    0.941715  \n",
      "17    0.944795  \n",
      "18    0.931718  \n",
      "19    0.578195  \n",
      "20    0.982470  \n",
      "21    0.818236  \n",
      "22    0.034207  \n",
      "23    0.041199  \n",
      "24    0.010371  \n",
      "25    0.112294  \n"
     ]
    }
   ],
   "source": [
    "# add the column of GAIN in df, which is the difference of the result column minus the baseline columns.\n",
    "# df[\"GAIN\"] = df[\"result\"] - df[\"baseline\"]\n",
    "df = df.set_index(\"metric\").loc[ORDER].reset_index()\n",
    "print(df.head(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4ca44e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Positive correlation\n",
    "POS = [\"pearson\", \"simVector\"]\n",
    "NEG = [\"mse\", \"naive\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7fcd0a2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{llll}\n",
      "\\toprule\n",
      "metric                             & baseline & result & GAIN                      \\\\\n",
      "\\midrule\n",
      "metric_gyr_pearson_X/test          & -0.06    & 0.10   & \\textcolor{red}{0.16}     \\\\\n",
      "metric_gyr_pearson_Y/test          & -0.09    & 0.25   & \\textcolor{red}{0.34}     \\\\\n",
      "metric_gyr_pearson_Z/test          & 0.75     & 0.98   & \\textcolor{red}{0.23}     \\\\\n",
      "metric_gyr_pearson_norm/test       & 0.84     & 0.84   & \\textcolor{green}{0.00}   \\\\\n",
      "metric_gyr_simVector_X/test        & -0.15    & 0.51   & \\textcolor{red}{0.66}     \\\\\n",
      "metric_gyr_simVector_Y/test        & -0.07    & 0.50   & \\textcolor{red}{0.57}     \\\\\n",
      "metric_gyr_simVector_Z/test        & 0.81     & 0.95   & \\textcolor{red}{0.14}     \\\\\n",
      "metric_gyr_simVector_norm/test     & 0.99     & 0.98   & \\textcolor{green}{-0.01}  \\\\\n",
      "metric_gyr_simVector/test          & 0.19     & 0.65   & \\textcolor{red}{0.46}     \\\\\n",
      "metric_naive_Angular_error_X/test  & 0.10     & 0.02   & \\textcolor{red}{-0.08}    \\\\\n",
      "metric_naive_Angular_error_Y/test  & 0.09     & 0.02   & \\textcolor{red}{-0.07}    \\\\\n",
      "metric_naive_Angular_error_Z/test  & 0.13     & 0.02   & \\textcolor{red}{-0.11}    \\\\\n",
      "metric_naive_Angular_error/test    & 0.57     & 0.07   & \\textcolor{red}{-0.50}    \\\\\n",
      "metric_acc_pearson_X/test          & 0.72     & 0.98   & \\textcolor{red}{0.26}     \\\\\n",
      "metric_acc_pearson_Y/test          & 0.46     & 0.98   & \\textcolor{red}{0.52}     \\\\\n",
      "metric_acc_pearson_Z/test          & -0.13    & 0.63   & \\textcolor{red}{0.76}     \\\\\n",
      "metric_acc_pearson_norm/test       & 0.58     & 0.94   & \\textcolor{red}{0.36}     \\\\\n",
      "metric_acc_simVector_X/test        & 0.68     & 0.94   & \\textcolor{red}{0.26}     \\\\\n",
      "metric_acc_simVector_Y/test        & 0.52     & 0.93   & \\textcolor{red}{0.41}     \\\\\n",
      "metric_acc_simVector_Z/test        & -0.09    & 0.58   & \\textcolor{red}{0.67}     \\\\\n",
      "metric_acc_simVector_norm/test     & 0.96     & 0.98   & \\textcolor{red}{0.02}     \\\\\n",
      "metric_acc_simVector/test          & 0.37     & 0.82   & \\textcolor{red}{0.45}     \\\\\n",
      "metric_naive_distance_error_X/test & 0.21     & 0.03   & \\textcolor{red}{-0.18}    \\\\\n",
      "metric_naive_distance_error_Y/test & 0.27     & 0.04   & \\textcolor{red}{-0.23}    \\\\\n",
      "metric_naive_distance_error_Z/test & 0.25     & 0.01   & \\textcolor{red}{-0.24}    \\\\\n",
      "metric_naive_distance_error/test   & 0.64     & 0.11   & \\textcolor{red}{-0.53}    \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n"
     ]
    }
   ],
   "source": [
    "# convert the df to latex format and for the GAIN column if the row name contains the keyword in POS means the positive correlation, so positive should be red and negative should be green. On the contrary, if the key contains the NEG any keywords then it means the negative relationship, where the negative should be red and positive should be green\n",
    "def generate_aligned_latex_table(df, pos_keywords, neg_keywords):\n",
    "    \"\"\"\n",
    "    Process a DataFrame by:\n",
    "      1. Coloring the 'GAIN' column based on the relationship found in the 'metric' column.\n",
    "      2. Combining baseline and result with their respective std columns, unless std is NaN.\n",
    "      3. Formatting all numeric columns (except 'GAIN') with .4f format.\n",
    "      4. Converting the DataFrame to a LaTeX table.\n",
    "      5. Post-processing the LaTeX string to align columns for easier editing.\n",
    "\n",
    "    Returns:\n",
    "      A well-aligned LaTeX table string.\n",
    "    \"\"\"\n",
    "\n",
    "    def color_gain(row):\n",
    "        metric = row[\"metric\"]\n",
    "        gain = row[\"GAIN\"]\n",
    "        is_pos = any(p in metric for p in pos_keywords)\n",
    "        is_neg = any(n in metric for n in neg_keywords)\n",
    "        if is_pos:\n",
    "            return (\n",
    "                r\"\\textcolor{red}{%.2f}\" % gain\n",
    "                if gain > 0\n",
    "                else r\"\\textcolor{green}{%.2f}\" % gain\n",
    "            )\n",
    "        elif is_neg:\n",
    "            return (\n",
    "                r\"\\textcolor{red}{%.2f}\" % gain\n",
    "                if gain < 0\n",
    "                else r\"\\textcolor{green}{%.2f}\" % gain\n",
    "            )\n",
    "        else:\n",
    "            return \"%.2f\" % gain\n",
    "\n",
    "    def format_with_std(value, std):\n",
    "        if pd.isna(std):\n",
    "            return f\"{value:.2f}\"\n",
    "        else:\n",
    "            return f\"{value:.2f} $\\pm$ {std:.2f}\"\n",
    "\n",
    "    def align_latex_table(latex_str):\n",
    "        lines = latex_str.splitlines()\n",
    "        table_rows = []\n",
    "        for idx, line in enumerate(lines):\n",
    "            if \"&\" in line and line.strip().endswith(r\"\\\\\"):\n",
    "                parts = line.rstrip().rstrip(r\"\\\\\").split(\" & \")\n",
    "                table_rows.append((idx, parts))\n",
    "\n",
    "        if not table_rows:\n",
    "            return latex_str\n",
    "\n",
    "        num_cols = len(table_rows[0][1])\n",
    "        col_widths = [0] * num_cols\n",
    "        for _, parts in table_rows:\n",
    "            for i, cell in enumerate(parts):\n",
    "                col_widths[i] = max(col_widths[i], len(cell))\n",
    "\n",
    "        for idx, parts in table_rows:\n",
    "            padded_parts = [cell.ljust(col_widths[i]) for i, cell in enumerate(parts)]\n",
    "            lines[idx] = \" & \".join(padded_parts) + r\" \\\\\"\n",
    "\n",
    "        return \"\\n\".join(lines)\n",
    "\n",
    "    df_copy = df.copy()\n",
    "\n",
    "    # Format baseline and result with std, skipping Â± if std is NaN\n",
    "    # df_copy[\"baseline\"] = df_copy.apply(\n",
    "    #     lambda row: format_with_std(row[\"baseline\"], row[\"baseline_std\"]), axis=1\n",
    "    # )\n",
    "    # df_copy[\"result\"] = df_copy.apply(\n",
    "    #     lambda row: format_with_std(row[\"result\"], row[\"result_std\"]), axis=1\n",
    "    # )\n",
    "\n",
    "    # Apply color formatting to GAIN\n",
    "\n",
    "    # Drop std columns\n",
    "    df_copy.drop(columns=[\"baseline_std\", \"result_std\"], inplace=True)\n",
    "    for col in [\"baseline\", \"result\"]:\n",
    "        if col in df_copy.columns:\n",
    "            df_copy[col] = df_copy[col].apply(\n",
    "                lambda x: round(x, 2) if pd.notna(x) else np.nan\n",
    "            )\n",
    "\n",
    "    df_copy[\"GAIN\"] = df_copy[\"result\"] - df_copy[\"baseline\"]\n",
    "    df_copy[\"GAIN\"] = df_copy.apply(color_gain, axis=1)\n",
    "    # Format baseline and result to .2f\n",
    "    for col in [\"baseline\", \"result\"]:\n",
    "        if col in df_copy.columns:\n",
    "            df_copy[col] = df_copy[col].apply(\n",
    "                lambda x: f\"{x:.2f}\" if pd.notna(x) else \"\"\n",
    "            )\n",
    "\n",
    "    # Format other numeric columns\n",
    "    for col in df_copy.columns:\n",
    "        if col not in [\"GAIN\", \"baseline\", \"result\"] and pd.api.types.is_numeric_dtype(\n",
    "            df_copy[col]\n",
    "        ):\n",
    "            df_copy[col] = df_copy[col].apply(\n",
    "                lambda x: f\"{x:.2f}\" if pd.notna(x) else \"\"\n",
    "            )\n",
    "\n",
    "    latex_str = df_copy.to_latex(index=False, escape=False)\n",
    "    aligned_latex_str = align_latex_table(latex_str)\n",
    "\n",
    "    return aligned_latex_str\n",
    "\n",
    "\n",
    "# Get the aligned LaTeX table string:\n",
    "latex_table = generate_aligned_latex_table(df, POS, NEG)\n",
    "print(latex_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b0e1146a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # convert the df to latex format and for the GAIN column if the row name contains the keyword in POS means the positive correlation, so positive should be red and negative should be green. On the contrary, if the key contains the NEG any keywords then it means the negative relationship, where the negative should be red and positive should be green\n",
    "# def color_gain(row):\n",
    "#     metric = row[\"metric\"]\n",
    "#     gain = row[\"GAIN\"]\n",
    "#     is_pos = any(p in metric for p in POS)\n",
    "#     is_neg = any(n in metric for n in NEG)\n",
    "#     if is_pos:\n",
    "#         # Positive correlation: positive gain is red, negative is green\n",
    "#         if gain > 0:\n",
    "#             return r\"\\textcolor{red}{%.4f}\" % gain\n",
    "#         else:\n",
    "#             return r\"\\textcolor{green}{%.4f}\" % gain\n",
    "#     elif is_neg:\n",
    "#         # Negative correlation: negative gain is red, positive is green\n",
    "#         if gain < 0:\n",
    "#             return r\"\\textcolor{red}{%.4f}\" % gain\n",
    "#         else:\n",
    "#             return r\"\\textcolor{green}{%.4f}\" % gain\n",
    "#     else:\n",
    "#         return \"%.4f\" % gain\n",
    "\n",
    "# df_latex = df.copy()\n",
    "# df_latex[\"GAIN\"] = df_latex.apply(color_gain, axis=1)\n",
    "# latex_str = df_latex.to_latex(index=False, escape=False)\n",
    "# print(latex_str)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diffusion",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
